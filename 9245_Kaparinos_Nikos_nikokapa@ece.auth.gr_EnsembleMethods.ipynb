{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About iPython Notebooks ##\n",
    "\n",
    "iPython Notebooks are interactive coding environments embedded in a webpage. You will be using iPython notebooks in this class. Make sure you fill in any place that says `# BEGIN CODE HERE #END CODE HERE`. After writing your code, you can run the cell by either pressing \"SHIFT\"+\"ENTER\" or by clicking on \"Run\" (denoted by a play symbol). Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All). \n",
    "\n",
    " **What you need to remember:**\n",
    "\n",
    "- Run your cells using SHIFT+ENTER (or \"Run cell\")\n",
    "- Write code in the designated areas using Python 3 only\n",
    "- Do not modify the code outside of the designated areas\n",
    "- In some cases you will also need to explain the results. There will also be designated areas for that. \n",
    "\n",
    "Fill in your **NAME** and **AEM** below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"Kaparinos Nikos\"\n",
    "AEM = \"9245\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1da26a63e48275bf64ed3608a92f75ac",
     "grade": false,
     "grade_id": "cell-28329c89a3d9ebb8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Assignment 3 - Ensemble Methods #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2e378be0e0c4ed85ebc6bcc53e256aa5",
     "grade": false,
     "grade_id": "cell-17ca53188deb1a2b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Welcome to your third assignment. This exercise will test your understanding on Ensemble Methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7fb9c467676bec1973d8e90bb815e23f",
     "grade": false,
     "grade_id": "cell-1a33a1efbf02238c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Always run this cell\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# USE THE FOLLOWING RANDOM STATE FOR YOUR CODE\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "aa2d11566658cb0f6d5ea19212a619de",
     "grade": false,
     "grade_id": "cell-7210caf6b2891007",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Download the Dataset ##\n",
    "Download the dataset using the following cell or from this [link](https://github.com/sakrifor/public/tree/master/machine_learning_course/EnsembleDataset) and put the files in the same folder as the .ipynb file. \n",
    "In this assignment you are going to work with a dataset originated from the [ImageCLEFmed: The Medical Task 2016](https://www.imageclef.org/2016/medical) and the **Compound figure detection** subtask. The goal of this subtask is to identify whether a figure is a compound figure (one image consists of more than one figure) or not. The train dataset consits of 4197 examples/figures and each figure has 4096 features which were extracted using a deep neural network. The *CLASS* column represents the class of each example where 1 is a compoung figure and 0 is not. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c426c8680b4b28c9595139bec1d32f27",
     "grade": false,
     "grade_id": "cell-a413577b7685bfbe",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('test_set_noclass.csv', <http.client.HTTPMessage at 0x1497c8db3d0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "url_train = 'https://github.com/sakrifor/public/raw/master/machine_learning_course/EnsembleDataset/train_set.csv'\n",
    "filename_train = 'train_set.csv'\n",
    "urllib.request.urlretrieve(url_train, filename_train)\n",
    "url_test = 'https://github.com/sakrifor/public/raw/master/machine_learning_course/EnsembleDataset/test_set_noclass.csv'\n",
    "filename_test = 'test_set_noclass.csv'\n",
    "urllib.request.urlretrieve(url_test, filename_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5e073a9f617d5e2e192ef70d370f000b",
     "grade": false,
     "grade_id": "cell-cbadea205635117c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell to load the data\n",
    "train_set = pd.read_csv(\"train_set.csv\").sample(frac=1).reset_index(drop=True)\n",
    "train_set.head()\n",
    "X = train_set.drop(columns=['CLASS'])\n",
    "y = train_set['CLASS'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e5c0ed51001ec5b7e6cdcef1303473e7",
     "grade": false,
     "grade_id": "cell-4f509bca5cb87e84",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 1.0 Testing different ensemble methods ##\n",
    "In this part of the assignment you are asked to create and test different ensemble methods using the train_set.csv dataset. You should use **10-fold cross validation** for your tests and report the average f-measure and accuracy of your models.\n",
    "\n",
    "### !!! Use n_jobs=-1 where is posibble to use all the cores of a machine for running your tests ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5d56eafac9ce59f34521ab931a24e9c8",
     "grade": false,
     "grade_id": "cell-db7468662add40fe",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1.1 Voting ###\n",
    "Create a voting classifier which uses three estimators/classifiers. Test both soft and hard voting and choose the best one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bbf11fd8382f22bddabe61416516e7be",
     "grade": true,
     "grade_id": "cell-3a1719cdb031d112",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scale', StandardScaler()),\n",
      "                ('vcls',\n",
      "                 VotingClassifier(estimators=[('cls1',\n",
      "                                               MLPClassifier(hidden_layer_sizes=50,\n",
      "                                                             random_state=42)),\n",
      "                                              ('cls2',\n",
      "                                               MLPClassifier(hidden_layer_sizes=(50,\n",
      "                                                                                 50),\n",
      "                                                             random_state=42)),\n",
      "                                              ('cls3',\n",
      "                                               MLPClassifier(hidden_layer_sizes=(50,\n",
      "                                                                                 50,\n",
      "                                                                                 50),\n",
      "                                                             random_state=42))]))])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   6 out of  10 | elapsed:  2.0min remaining:  1.3min\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:  2.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     fit_time  score_time  test_accuracy   test_f1\n",
      "0  117.529907    0.083073       0.857143  0.877551\n",
      "1  116.957398    0.112101       0.850000  0.876712\n",
      "2  117.919256    0.081074       0.871429  0.892430\n",
      "3  117.214613    0.095087       0.861905  0.885375\n",
      "4  115.064306    0.141777       0.864286  0.887129\n",
      "5  115.297407    0.128049       0.852381  0.875000\n",
      "6  113.735050    0.135124       0.849642  0.873239\n",
      "7  113.190559    0.132122       0.854415  0.872651\n",
      "8   47.387132    0.063108       0.835322  0.857143\n",
      "9   46.247769    0.070063       0.873508  0.895464\n",
      "\n",
      "Execution time = 161.27 second(s)\n"
     ]
    }
   ],
   "source": [
    "# BEGIN CODE HERE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import time\n",
    "\n",
    "# Options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "start = time.perf_counter()\n",
    "# print(X.info())\n",
    "\n",
    "# Classifiers\n",
    "cls1 = MLPClassifier(hidden_layer_sizes=(50), random_state=RANDOM_STATE)\n",
    "cls2 = MLPClassifier(hidden_layer_sizes=(50, 50), random_state=RANDOM_STATE)\n",
    "cls3 = MLPClassifier(hidden_layer_sizes=(50, 50, 50), random_state=RANDOM_STATE)\n",
    "vcls = VotingClassifier(estimators=[\n",
    "    ('cls1', cls1), ('cls2', cls2), ('cls3', cls3)],\n",
    "    voting='hard')\n",
    "\n",
    "# Pipeline\n",
    "pipe = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('vcls', vcls)])\n",
    "print(pipe)\n",
    "\n",
    "# Cross validate\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=RANDOM_STATE)\n",
    "cv_results = cross_validate(pipe, X, y, cv=cv, n_jobs=8, verbose=1, scoring=['accuracy', 'f1'])\n",
    "cv_results = pd.DataFrame(cv_results)\n",
    "print(cv_results)\n",
    "\n",
    "# Average results\n",
    "avg_fmeasure = cv_results['test_accuracy'].mean()  # The average f-measure\n",
    "avg_accuracy = cv_results['test_f1'].mean()  # The average accuracy\n",
    "\n",
    "# Execution Time\n",
    "end = time.perf_counter()\n",
    "print(f\"\\nExecution time = {end - start:.2f} second(s)\")\n",
    "# END CODE HERE\n",
    "#END CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2f0e52e5eea2eb2cb23380c80ff846cf",
     "grade": false,
     "grade_id": "cell-0ef59e80595937ed",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier:\n",
      "VotingClassifier(estimators=[('cls1', SVC(gamma=1, random_state=0)),\n",
      "                             ('cls2',\n",
      "                              MLPClassifier(hidden_layer_sizes=(50, 50),\n",
      "                                            random_state=42)),\n",
      "                             ('cls3', DecisionTreeClassifier(random_state=0))])\n",
      "F1-Score:0.7866967837254234 & Accuracy:0.8386478884439328\n"
     ]
    }
   ],
   "source": [
    "print(\"Classifier:\")\n",
    "print(vcls)\n",
    "print(\"F1-Score:{} & Accuracy:{}\".format(avg_fmeasure,avg_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8c7e6ab511ff3a546d2e2efb5feb892f",
     "grade": false,
     "grade_id": "cell-f6d620a3fd102626",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1.2 Stacking ###\n",
    "Create a stacking classifier which uses two estimators/classifiers. Try different classifiers for the combination of the initial classifiers. Report your results in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bc7e22a168b668cbd10c524297950133",
     "grade": true,
     "grade_id": "cell-2ae5e38bd546681e",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# BEGIN CODE HERE\n",
    "\n",
    "cls1 = \"\" # Classifier #1 \n",
    "cls2 = \"\" # Classifier #2 \n",
    "scls = \"\" # Stacking Classifier\n",
    "avg_fmeasure = 0 # The average f-measure\n",
    "avg_accuracy = 0 # The average accuracy\n",
    "\n",
    "#END CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1a27a3122627aed7d5a6f5678055f712",
     "grade": false,
     "grade_id": "cell-6d6cadab378a2b03",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print(\"Classifier:\")\n",
    "print(scls)\n",
    "print(\"F1-Score:{} & Accuracy:{}\".format(avg_fmeasure,avg_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a6b0c745a12e384341f4e246c5242d25",
     "grade": false,
     "grade_id": "cell-8a05446ba9a944c3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1.3 Report the results ###  \n",
    "Report the results of your experiments in the following cell. How did you choose your initial classifiers? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e3da261e2e18ede4c057e21e080b9bac",
     "grade": true,
     "grade_id": "cell-1522ee0b7c414fba",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "***\n",
    "<font size=\"4\">**1.1 Voting**</font>\n",
    "\n",
    "\n",
    "Both homogenous and heterogenious voting classifiers were experimented with. The goal when using ensemble techniques, like voting, is to use models that have different behaviours. This means that the models used should should provide correct predictions on different subsets of the dataset. Then, the ensembling of those models will probably improve overall performance. Also, every model on its own should be as accurate as possible, provided the above statement holds true.\n",
    "\n",
    "To build models that perform differently, two aproaches were followed. Using heterogeneous models and using homegenous models with varying hyperparameter values.\n",
    "\n",
    "<font size=\"3\">**Homogeneous**</font>\n",
    "* Decision Tree Classifiers:\n",
    "    Decision Trees with different maximum depths were used.<br>\n",
    "    \n",
    "    Classifiers Used:\n",
    "        1) DecisionTreeClassifier(random_state=RANDOM_STATE)\n",
    "        2) DecisionTreeClassifier(max_depth=10, random_state=RANDOM_STATE)\n",
    "        3) DecisionTreeClassifier(max_depth=5, random_state=RANDOM_STATE)\n",
    "\n",
    "\n",
    "   \n",
    "\n",
    "| Voting Type | F1 Score | Accuracy |\n",
    "| --- | --- | --- |\n",
    "| Soft | 0.7214  | 0.7670 |\n",
    "| Hard | 0.7221 | 0.7670 |\n",
    "\n",
    "* Support Vector Machine Classifiers:\n",
    "    SVMs with different gamma values were used.<br>\n",
    "    \n",
    "    Classifiers Used:\n",
    "        1) SVC(gamma=1, kernel='rbf', random_state=RANDOM_STATE)\n",
    "        2) SVC(gamma=0.5, kernel='rbf', random_state=RANDOM_STATE)\n",
    "        3) SVC(gamma=1.5, kernel='rbf', random_state=RANDOM_STATE)\n",
    "        \n",
    "| Voting Type | F1 Score | Accuracy |\n",
    "| --- | --- | --- |\n",
    "| Soft | 0.5879  | 0.7405 |\n",
    "| Hard | 0.5879 | 0.7405 |\n",
    "\n",
    "* Neural Network classifiers:\n",
    "    Multi-layer perceptrons with different number of layers were used.<br>\n",
    "    \n",
    "    Classifiers Used:\n",
    "        1) MLPClassifier(hidden_layer_sizes=(50), random_state=RANDOM_STATE)\n",
    "        2) MLPClassifier(hidden_layer_sizes=(50, 50), random_state=RANDOM_STATE)\n",
    "        3) MLPClassifier(hidden_layer_sizes=(50, 50, 50), random_state=RANDOM_STATE)\n",
    "        \n",
    "| Voting Type | F1 Score | Accuracy |\n",
    "| --- | --- | --- |\n",
    "| Soft | 0.8558  | 0.8780 |\n",
    "| Hard | 0.8580 | 0.8797 |\n",
    "\n",
    "<font size=\"3\">**Heterogeneous**</font>\n",
    "* Heterogeneous model:\n",
    "     A combination of the classifiers mentioned above was used.<br>\n",
    "       \n",
    "       Classifiers Used:\n",
    "        1) DecisionTreeClassifier(random_state=RANDOM_VARIABLE)\n",
    "        2) MLPClassifier(hidden_layer_sizes=(50, 50), random_state=RANDOM_VARIABLE)\n",
    "        3) SVC(gamma=1, random_state=RANDOM_VARIABLE)\n",
    "        \n",
    "| Voting Type | F1 Score | Accuracy |\n",
    "| --- | --- | --- |\n",
    "| Soft | 0.7753  | 0.8270 |\n",
    "| Hard | 0.7855 | 0.8371 |\n",
    "\n",
    "<font size=\"3\">**Voting Report**</font>\n",
    "\n",
    "In the experiments made, hard voting has been consistently outperforming soft voting. Also, the use of voting as an ensemble technique, improved the model performance compared to single models.\n",
    "\n",
    "***\n",
    "<font size=\"4\">**1.2 Stacking**</font>\n",
    "\n",
    "The 3 types of classifier mentioned above were used in combinations of 2 for stacking. The meta estimator used is logistic regression. The output of the estimators can be either a probability or simply a class prediction. Also, the input data can be passed through to the meta estimator in addition to the model predictions. Stacking estimators were created testing all 4 possible options (probability and passthrough, prediction and passthrough, probability and not passthrough, prediction and not passthrough).\n",
    "\n",
    "<font size=\"3\">**Stacking Results**</font>\n",
    "\n",
    "<font size=\"2\">**Decision Tree and Support Vector Machine**</font>\n",
    "\n",
    "Accuracy:\n",
    "\n",
    "|  | Probability | Prediction |\n",
    "| --- | --- | --- |\n",
    "| Passthrough |0.8291  |0.8276 |\n",
    "| Not Passthrough |0.7223 |0.7183  |\n",
    "\n",
    "F1 Score:\n",
    "\n",
    "\n",
    "|  | Probability | Prediction |\n",
    "| --- | --- | --- |\n",
    "| Passthrough |0.8545  |0.8536 |\n",
    "| Not Passthrough |0.7689 |0.7632  |\n",
    "\n",
    "<font size=\"2\">**Decision Tree and Multi-Layer Perceptron**</font>\n",
    "\n",
    "Accuracy:\n",
    "\n",
    "\n",
    "|  | Probability | Prediction |\n",
    "| --- | --- | --- |\n",
    "| Passthrough |0.8296  |0.8329 |\n",
    "| Not Passthrough |0.8560 | 0.8551 |\n",
    "\n",
    "F1 Score:\n",
    "\n",
    "\n",
    "|  | Probability | Prediction |\n",
    "| --- | --- | --- |\n",
    "| Passthrough |0.8554  |0.8580 |\n",
    "| Not Passthrough |0.8789 | 0.8775 |\n",
    "\n",
    "<font size=\"2\">**Support Vector Machine and Multi-Layer Perceptron**</font>\n",
    "\n",
    "Accuracy:\n",
    "\n",
    "\n",
    "|  | Probability | Prediction |\n",
    "| --- | --- | --- |\n",
    "| Passthrough | :0.8269 |0.8310 |\n",
    "| Not Passthrough |0.8522 |0.8548  |\n",
    "\n",
    "F1 Score:\n",
    "\n",
    "\n",
    "|  | Probability | Prediction |\n",
    "| --- | --- | --- |\n",
    "| Passthrough |0.8524 |0.8563 |\n",
    "| Not Passthrough |0.8747 | 0.8769 |\n",
    "\n",
    "<font size=\"3\">**Stacking Report**</font>\n",
    "\n",
    "Stacking, like voting before, improved the model performance compared to single models. Passing through the input data and the type of output from the base models provided inconsistent results. Depending on the combination of base models, different stacking methods were optimal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d7520f22a6a708d14fa6d56d42b78d9f",
     "grade": false,
     "grade_id": "cell-b40c3a7c4ef32588",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 2.0 Randomization ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5073f6ead7355190904470c661d86d53",
     "grade": false,
     "grade_id": "cell-64c9c6881b26f5bb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**2.1** You are asked to create three ensembles of decision trees where each one uses a different method for producing homogeneous ensembles. Compare them with a simple decision tree classifier and report your results in the dictionaries (dict) below using as key the given name of your classifier and as value the f1/accuracy score. The dictionaries should contain four different elements.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1661b594e02f8f8a73ceaad8f03b85a3",
     "grade": true,
     "grade_id": "cell-9e760b938516b506",
     "locked": false,
     "points": 30,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# BEGIN CODE HERE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import\n",
    "ens1 = \"\"\n",
    "ens2 = \"\"\n",
    "ens3 = \"\"\n",
    "tree = \"\"\n",
    "\n",
    "f_measures = dict()\n",
    "accuracies = dict()\n",
    "# Example f_measures = {'Simple Decision':0.8551, 'Ensemble with random ...': 0.92, ...}\n",
    "\n",
    "\n",
    "#END CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0da6aad44e9bd8a9f7cc06eccec886c0",
     "grade": false,
     "grade_id": "cell-77f4dc2cd4cb2f7e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print(ens1)\n",
    "print(ens2)\n",
    "print(ens3)\n",
    "print(tree)\n",
    "for name,score in f_measures.items():\n",
    "    print(\"Classifier:{} -  F1:{}\".format(name,score))\n",
    "for name,score in accuracies.items():\n",
    "    print(\"Classifier:{} -  Accuracy:{}\".format(name,score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "48f3eafac80f6dd15441c4991c78836d",
     "grade": false,
     "grade_id": "cell-a6ea07f0be814a40",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**2.2** Describe your classifiers and your results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9395efc3b936166e55b3bec6e0afdab3",
     "grade": true,
     "grade_id": "cell-399fc5e7254f1c58",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "***\n",
    "<font size=\"3\">**Randomization Report**</font>\n",
    "\n",
    "The three ensembles that were used are:\n",
    "\n",
    "Random Forest<br>\n",
    "Bagging<br>\n",
    "Ada Boost<br>\n",
    "\n",
    "These ensembles were compared to a standard decision tree classifier. A grid search based on accuracy was conducted for each classifier in order to tune its hyper-parameters. All three ensembles provided substantial performance gains over the simple decision tree. Their performance was very similar, however the Ada Boost ensemble slightly outperformed the other two in both Accuracy and F1 metrics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f8edad6471eab5b0645f6ca46bab2f7a",
     "grade": false,
     "grade_id": "cell-a0de461bc76e0880",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**2.3** Increasing the number of estimators in a bagging classifier can drastically increase the training time of a classifier. Is there any solution to this problem? Can the same solution be applied to boosting classifiers?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c9573961dbe26d9ce6669df5da70a45a",
     "grade": true,
     "grade_id": "cell-0a28025407c78a48",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "A bagging classifier can be trained in a parallel or distributed environment, thus theoretically massively improving training time. This approach cannot be applied to boosting classifiers, because every model is trained sequentially, since it needs the output of the previous model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d016d23320010c4d8d9e8218cba553e8",
     "grade": false,
     "grade_id": "cell-35e46873d8c6537c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 3.0 Creating the best classifier ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e7e2a127a27e4c9131e94ae73e6e325b",
     "grade": false,
     "grade_id": "cell-6de6582e696ba2d8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**3.1** In this part of the assignment you are asked to train the best possible ensemble! Describe the process you followed to achieve this result. How did you choose your classifier and your parameters and why. Report the f-measure & accuracy (10-fold cross validation) of your final classifier and results of classifiers you tried in the cell following the code. Can you achieve an accuracy over 83-84%?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f8d58b62ea96a7e0e0776f79c58e4b10",
     "grade": true,
     "grade_id": "cell-d1bba508731c9030",
     "locked": false,
     "points": 20,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# BEGIN CODE HERE\n",
    "best_cls = \"\"\n",
    "\n",
    "best_fmeasure = \"\"\n",
    "best_accuracy = \"\"\n",
    "\n",
    "\n",
    "#END CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1ecc691ce956fad47c497b9849747c34",
     "grade": false,
     "grade_id": "cell-39673f451b660dcc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print(\"Classifier:\")\n",
    "print(best_cls)\n",
    "print(\"F1-Score:{} & Accuracy:{}\".format(best_fmeasure,best_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "667632db5afb6f143062507bae31063f",
     "grade": false,
     "grade_id": "cell-6a072817c64ce4a1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**3.2** Describe the process you followed to achieve this result. How did you choose your classifier and your parameters and why. Report the f-measure & accuracy (10-fold cross validation) of your final classifier and results of classifiers you tried in the cell following the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3abcb52a70fcb6da4f93980026b8e593",
     "grade": true,
     "grade_id": "cell-5f1d5ba45ffeb074",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "***\n",
    "<font size=\"3\">**Approach**</font>\n",
    "\n",
    "The approach that was followed was tuning the hyper-parameters of various models and then using them as base models in voting and stacking ensembles. Models with good performance will most likely be the best candidates to be used as base models. Thus an extensive grid search based on accuracy was conducted for each model. However, since base models that behave differently usually provide the best results when ensembled, experiments should also be made with sub optimal models. These sub optimal models can either have different hyper-parameter values than the best models, or they can simple be different types of classifiers. \n",
    "\n",
    "<font size=\"3\">**Results**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "22500bda285c8dc9375ee048e883be55",
     "grade": false,
     "grade_id": "cell-5b27d068d1fbfa37",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**3.3** Create a classifier that is going to be used in production - in a live system. Use the *test_set_noclass.csv* to make predictions. Store the predictions in a list.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c40bf6a2d6e630b217742246c20d2560",
     "grade": true,
     "grade_id": "cell-ab69a2863e87fd72",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# BEGIN CODE HERE\n",
    "cls = \"\"\n",
    "predictions = []\n",
    "\n",
    "#END CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ace9dbe06e5607ddf9353befef8472c0",
     "grade": false,
     "grade_id": "cell-d98d6687c3bbe4ee",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print(cls)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1af1d441fd486d53e45173d4f352ba8c",
     "grade": false,
     "grade_id": "cell-966633c679d5c960",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "LEAVE HERE ANY COMMENTS ABOUT YOUR CLASSIFIER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "24dbe2151df25b6e5b36e988a8e38dcb",
     "grade": false,
     "grade_id": "cell-78ffc0c68225fb1a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### This following cell will not be executed. The test_set.csv with the classes will be made available after the deadline and this cell is for testing purposes!!! Do not modify it! ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ddcf51aaeaaa305540873fd0012a4b06",
     "grade": false,
     "grade_id": "cell-7946d9ee342bf549",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score,accuracy_score\n",
    "final_test_set = pd.read_csv('test_set.csv')\n",
    "ground_truth = final_test_set['CLASS']\n",
    "print(\"Accuracy:{}\".format(accuracy_score(predictions,ground_truth)))\n",
    "print(\"F1-Score:{}\".format(f1_score(predictions,ground_truth)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
